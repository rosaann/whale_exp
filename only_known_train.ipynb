{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from fastai.vision import *\n",
    "from fastai.metrics import accuracy\n",
    "from fastai.basic_data import *\n",
    "from skimage.util import montage\n",
    "import pandas as pd\n",
    "from torch import optim\n",
    "import re\n",
    "\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I take a curriculum approach to training here. I first expose the model to as many different images of whales as quickly as possible (no oversampling) and train on images resized to 224x224.\n",
    "\n",
    "I would like the conv layers to start picking up on features useful for identifying whales. For that, I want to show the model as rich of a dataset as possible.\n",
    "\n",
    "I then train on images resized to 448x448.\n",
    "\n",
    "Finally, I train on oversampled data. Here, the model will see some images more often than others but I am hoping that this will help alleviate the class imbalance in the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fastai\n",
    "from fastprogress import force_console_behavior\n",
    "import fastprogress\n",
    "fastprogress.fastprogress.NO_BAR = True\n",
    "master_bar, progress_bar = force_console_behavior()\n",
    "fastai.basic_train.master_bar, fastai.basic_train.progress_bar = master_bar, progress_bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../train.csv')\n",
    "val_fns = {'69823499d.jpg'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn2label = {row[1].Image: row[1].Id for row in df.iterrows()}\n",
    "path2fn = lambda path: re.search('\\w*\\.jpg$', path).group(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = f'res50-full-train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "SZ = 224\n",
    "BS = 64\n",
    "NUM_WORKERS = 12\n",
    "SEED=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = (\n",
    "    ImageItemList\n",
    "        .from_df(df[df.Id != 'new_whale'], '../train', cols=['Image'])\n",
    "        .split_by_valid_func(lambda path: path2fn(path) in val_fns)\n",
    "        .label_from_func(lambda path: fn2label[path2fn(path)])\n",
    "        .add_test(ImageItemList.from_folder('../test'))\n",
    "        .transform(get_transforms(do_flip=False), size=SZ, resize_method=ResizeMethod.SQUISH)\n",
    "        .databunch(bs=BS, num_workers=NUM_WORKERS, path='data')\n",
    "        .normalize(imagenet_stats)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet50-19c8e357.pth\" to /root/.torch/models/resnet50-19c8e357.pth\n",
      "100%|██████████| 102502400/102502400 [00:10<00:00, 9398437.37it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch     train_loss  valid_loss\n",
      "1         7.556172    1.095479    \n",
      "2         6.803409    2.701401    \n",
      "3         6.085203    3.106928    \n",
      "4         5.230840    0.661968    \n",
      "5         4.280574    1.174970    \n",
      "6         3.516786    0.222890    \n",
      "7         2.646444    0.007958    \n",
      "8         1.904013    2.486029    \n",
      "9         1.184974    0.064373    \n",
      "10        0.731920    0.014410    \n",
      "11        0.414916    0.000007    \n",
      "12        0.205693    0.000074    \n",
      "13        0.125785    0.000093    \n",
      "14        0.105435    0.000041    \n",
      "epoch     train_loss  valid_loss\n",
      "1         0.105492    0.000017    \n",
      "2         0.123349    0.000099    \n",
      "3         0.154840    0.000008    \n",
      "4         0.208754    0.000013    \n",
      "5         0.250755    0.000130    \n",
      "6         0.291193    0.000145    \n",
      "7         0.320904    0.000001    \n",
      "8         0.312296    0.000006    \n",
      "9         0.288110    0.000004    \n",
      "10        0.261304    0.000013    \n",
      "11        0.216555    0.000002    \n",
      "12        0.174737    0.000000    \n",
      "13        0.172770    0.000006    \n",
      "14        0.154311    0.000000    \n",
      "15        0.116343    0.000000    \n",
      "16        0.103118    0.000000    \n",
      "17        0.077877    0.000004    \n",
      "18        0.053848    0.000006    \n",
      "19        0.048084    0.000002    \n",
      "20        0.042563    0.000000    \n",
      "21        0.034598    0.000000    \n",
      "22        0.032233    0.000000    \n",
      "23        0.036884    0.000000    \n",
      "24        0.027442    0.000000    \n",
      "CPU times: user 36min 59s, sys: 13min 50s, total: 50min 49s\n",
      "Wall time: 53min 37s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "learn = create_cnn(data, models.resnet50, lin_ftrs=[2048])\n",
    "learn.clip_grad();\n",
    "\n",
    "learn.fit_one_cycle(14, 1e-2)\n",
    "learn.save(f'{name}-stage-1')\n",
    "\n",
    "learn.unfreeze()\n",
    "\n",
    "max_lr = 1e-3\n",
    "lrs = [max_lr/100, max_lr/10, max_lr]\n",
    "\n",
    "learn.fit_one_cycle(24, lrs)\n",
    "learn.save(f'{name}-stage-2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "SZ = 224 * 2\n",
    "BS = 64 // 4\n",
    "NUM_WORKERS = 12\n",
    "SEED=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = (\n",
    "    ImageItemList\n",
    "        .from_df(df[df.Id != 'new_whale'], '../train', cols=['Image'])\n",
    "        .split_by_valid_func(lambda path: path2fn(path) in val_fns)\n",
    "        .label_from_func(lambda path: fn2label[path2fn(path)])\n",
    "        .add_test(ImageItemList.from_folder('../test'))\n",
    "        .transform(get_transforms(do_flip=False), size=SZ, resize_method=ResizeMethod.SQUISH)\n",
    "        .databunch(bs=BS, num_workers=NUM_WORKERS, path='data')\n",
    "        .normalize(imagenet_stats)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch     train_loss  valid_loss\n",
      "1         1.236716    0.000023    \n",
      "2         0.916667    0.000001    \n",
      "3         1.244157    0.000018    \n",
      "4         1.739386    0.000000    \n",
      "5         1.922417    0.000000    \n",
      "6         1.645968    0.000015    \n",
      "7         1.505456    0.000002    \n",
      "8         1.231914    0.000000    \n",
      "9         1.049673    0.000000    \n",
      "10        0.744415    0.000000    \n",
      "11        0.659144    0.000000    \n",
      "12        0.533434    0.000000    \n",
      "epoch     train_loss  valid_loss\n",
      "1         0.531848    0.000000    \n",
      "2         0.475978    0.000000    \n",
      "3         0.524216    0.000001    \n",
      "4         0.595996    0.000000    \n",
      "5         0.607106    0.000002    \n",
      "6         0.656443    0.000003    \n",
      "7         0.746673    0.000000    \n",
      "8         0.673066    0.000000    \n",
      "9         0.617077    0.000000    \n",
      "10        0.627019    0.000007    \n",
      "11        0.627812    0.000000    \n",
      "12        0.613193    0.000000    \n",
      "13        0.596159    0.000000    \n",
      "14        0.500447    0.000000    \n",
      "15        0.526968    0.000000    \n",
      "16        0.470318    0.000001    \n",
      "17        0.448072    0.000000    \n",
      "18        0.412925    0.000000    \n",
      "19        0.407722    0.000000    \n",
      "20        0.395899    0.000000    \n",
      "21        0.342318    0.000000    \n",
      "22        0.389718    0.000000    \n",
      "CPU times: user 2h 3min 35s, sys: 49min 11s, total: 2h 52min 47s\n",
      "Wall time: 2h 53min 43s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "learn = create_cnn(data, models.resnet50, lin_ftrs=[2048])\n",
    "learn.clip_grad();\n",
    "learn.load(f'{name}-stage-2')\n",
    "learn.freeze_to(-1)\n",
    "\n",
    "learn.fit_one_cycle(12, 1e-2 / 4)\n",
    "learn.save(f'{name}-stage-3')\n",
    "\n",
    "learn.unfreeze()\n",
    "\n",
    "max_lr = 1e-3 / 4\n",
    "lrs = [max_lr/100, max_lr/10, max_lr]\n",
    "\n",
    "learn.fit_one_cycle(22, lrs)\n",
    "learn.save(f'{name}-stage-4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with oversampling\n",
    "df = pd.read_csv('data/oversampled_train_and_val.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = (\n",
    "    ImageItemList\n",
    "        .from_df(df, '../train', cols=['Image'])\n",
    "        .split_by_valid_func(lambda path: path2fn(path) in val_fns)\n",
    "        .label_from_func(lambda path: fn2label[path2fn(path)])\n",
    "        .add_test(ImageItemList.from_folder('../test'))\n",
    "        .transform(get_transforms(do_flip=False), size=SZ, resize_method=ResizeMethod.SQUISH)\n",
    "        .databunch(bs=BS, num_workers=NUM_WORKERS, path='data')\n",
    "        .normalize(imagenet_stats)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch     train_loss  valid_loss\n",
      "1         1.701043    0.000080    \n",
      "2         0.661639    0.000065    \n",
      "epoch     train_loss  valid_loss\n",
      "1         0.770123    0.001406    \n",
      "2         0.779335    0.000061    \n",
      "3         0.623801    0.000064    \n",
      "CPU times: user 1h 26min 55s, sys: 34min 36s, total: 2h 1min 31s\n",
      "Wall time: 2h 1min 39s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "learn = create_cnn(data, models.resnet50, lin_ftrs=[2048])\n",
    "learn.clip_grad();\n",
    "learn.load(f'{name}-stage-4')\n",
    "learn.freeze_to(-1)\n",
    "\n",
    "learn.fit_one_cycle(2, 1e-2 / 4)\n",
    "learn.save(f'{name}-stage-5')\n",
    "\n",
    "learn.unfreeze()\n",
    "\n",
    "max_lr = 1e-3 / 4\n",
    "lrs = [max_lr/100, max_lr/10, max_lr]\n",
    "\n",
    "learn.fit_one_cycle(3, lrs)\n",
    "learn.save(f'{name}-stage-6')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds, _ = learn.get_preds(DatasetType.Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = torch.cat((preds, torch.ones_like(preds[:, :1])), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds[:, 5004] = 0.06"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = learn.data.classes + ['new_whale']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_submission(preds, learn.data, name, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image</th>\n",
       "      <th>Id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a35964195.jpg</td>\n",
       "      <td>new_whale w_ffe8693 w_e0b6a42 w_4d06559 w_fd51859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>43fe9e728.jpg</td>\n",
       "      <td>new_whale w_ffe8693 w_d573a68 w_b26e855 w_de1dc14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0359ba961.jpg</td>\n",
       "      <td>new_whale w_ffe8693 w_6332313 w_0a8a451 w_dfbf100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7bb7fce17.jpg</td>\n",
       "      <td>new_whale w_ffe8693 w_8eb9c42 w_44c1eef w_c028816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>39a6f1f53.jpg</td>\n",
       "      <td>new_whale w_ffe8693 w_ee05147 w_bdb3a05 w_df1cc01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Image                                                 Id\n",
       "0  a35964195.jpg  new_whale w_ffe8693 w_e0b6a42 w_4d06559 w_fd51859\n",
       "1  43fe9e728.jpg  new_whale w_ffe8693 w_d573a68 w_b26e855 w_de1dc14\n",
       "2  0359ba961.jpg  new_whale w_ffe8693 w_6332313 w_0a8a451 w_dfbf100\n",
       "3  7bb7fce17.jpg  new_whale w_ffe8693 w_8eb9c42 w_44c1eef w_c028816\n",
       "4  39a6f1f53.jpg  new_whale w_ffe8693 w_ee05147 w_bdb3a05 w_df1cc01"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(f'subs/{name}.csv.gz').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(f'subs/{name}.csv.gz').Id.str.split().apply(lambda x: x[0] == 'new_whale').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 183k/183k [00:04<00:00, 37.6kB/s]\n",
      "Successfully submitted to Humpback Whale Identification"
     ]
    }
   ],
   "source": [
    "!kaggle competitions submit -c humpback-whale-identification -f subs/{name}.csv.gz -m \"{name}\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
